{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_hw.ipynb","provenance":[{"file_id":"1llC0SVGV9W_Q9X7a4y1EPxkXBac4OJKE","timestamp":1658943874534}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler"],"metadata":{"id":"-EOcUFqnyr-5","executionInfo":{"status":"ok","timestamp":1659110260519,"user_tz":-480,"elapsed":633,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"mQbDM1IWQZqL","executionInfo":{"status":"ok","timestamp":1659110261082,"user_tz":-480,"elapsed":9,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Hyper-parameters\n","num_epochs = 10\n","batch_size = 1\n","learning_rate = 0.01"],"metadata":{"id":"L2VrithpQbmK","executionInfo":{"status":"ok","timestamp":1659110261083,"user_tz":-480,"elapsed":10,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class IrisDataset(Dataset):\n","\n","    # data loading\n","    def __init__(self):\n","        iris = datasets.load_iris()\n","        feature = pd.DataFrame(iris.data, columns=iris.feature_names)\n","        target = pd.DataFrame(iris.target, columns=['target'])\n","        iris_data = pd.concat([target, feature], axis=1)\n","        # Data type change and flatten targets\n","        self.x = torch.from_numpy(np.array(iris_data)[:, 1:].astype(np.float32))\n","        self.y = torch.from_numpy(np.array(iris_data)[:, [0]].astype(np.longlong).flatten())\n","        self.n_samples = self.x.shape[0]\n","\n","    # working for indexing\n","    def __getitem__(self, index):\n","        \n","        return self.x[index], self.y[index]\n","\n","    # return the length of our dataset\n","    def __len__(self):\n","\n","        return self.n_samples\n","\n","\n","dataset = IrisDataset()\n","\n","# create data spliter\n","def dataSplit(dataset, val_split=0.2, shuffle=False, random_seed=0):\n","\n","    dataset_size = len(dataset)\n","    indices = list(range(dataset_size))\n","    split = int(np.floor(val_split * dataset_size))\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","    \n","    train_indices, val_indices = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_indices)\n","    valid_sampler = SubsetRandomSampler(val_indices)\n","\n","    return train_sampler , valid_sampler\n","\n","\n","train_sampler, valid_sampler = dataSplit(dataset = dataset, val_split = 0.2, shuffle = True, random_seed = 0)\n","\n","train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","val_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"],"metadata":{"id":"heE_aS9jQfM1","executionInfo":{"status":"ok","timestamp":1659110261083,"user_tz":-480,"elapsed":10,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        self.fc1 = nn.Linear(in_features=4, out_features=24)\n","        self.fc2 = nn.Linear(in_features=24, out_features=24)\n","        self.fc3 = nn.Linear(in_features=24, out_features=3)\n","\n","        \n","    def forward(self, net):\n","        net = F.relu(self.fc1(net))\n","        net = F.relu(self.fc2(net))\n","        net = self.fc3(net)\n","\n","        return net\n","\n","model = Network()\n","model.to(device)"],"metadata":{"id":"tQ7hBl1bPwAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659110261084,"user_tz":-480,"elapsed":10,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}},"outputId":"545dd8a6-1abb-4ce7-c74f-9a28fab6964c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Network(\n","  (fc1): Linear(in_features=4, out_features=24, bias=True)\n","  (fc2): Linear(in_features=24, out_features=24, bias=True)\n","  (fc3): Linear(in_features=24, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["lossfunc = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"metadata":{"id":"cT6KDBDRQmOs","executionInfo":{"status":"ok","timestamp":1659110261085,"user_tz":-480,"elapsed":10,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["min_valid_loss = np.inf\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    for i, (images, labels) in enumerate(train_loader):\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      \n","      outputs = model(images)\n","      loss = lossfunc(outputs, labels)\n","      \n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      train_loss += loss.item()\n","\n","           \n","    model.eval()\n","    n_correct = 0\n","    n_sample = 0\n","    with torch.no_grad():\n","      for (images, labels) in (val_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        val_loss = lossfunc(outputs, labels)\n","\n","        predicted = model(images)\n","        predicted = torch.argmax(predicted,1)\n","        n_sample += labels.size(0)\n","        n_correct += ( labels.view(-1) == predicted ).sum().item()\n","\n","    print('In epoch {}, loss: {:.3f}, val acc: {:.3f}, val_loss: {:.3f}'.format(\n","              epoch+1, train_loss/len(train_loader), n_correct/n_sample, val_loss))\n","    \n","    if min_valid_loss > val_loss:\n","      print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{val_loss:.6f}) \\t Saving The Model')\n","      min_valid_loss = val_loss\n","      # Saving State Dict\n","      torch.save(model.state_dict(), 'saved_model.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4SobhfSQqPW","executionInfo":{"status":"ok","timestamp":1659110262473,"user_tz":-480,"elapsed":1398,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}},"outputId":"7f6b4bb5-2f05-41bf-e7cd-9c08aeac1c99"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["In epoch 1, loss: 1.081, val acc: 0.467, val_loss: 1.063\n","Validation Loss Decreased(inf--->1.062738) \t Saving The Model\n","In epoch 2, loss: 0.968, val acc: 0.567, val_loss: 0.710\n","Validation Loss Decreased(1.062738--->0.709878) \t Saving The Model\n","In epoch 3, loss: 0.693, val acc: 0.567, val_loss: 1.323\n","In epoch 4, loss: 0.502, val acc: 0.567, val_loss: 0.247\n","Validation Loss Decreased(0.709878--->0.246780) \t Saving The Model\n","In epoch 5, loss: 0.419, val acc: 0.767, val_loss: 0.027\n","Validation Loss Decreased(0.246780--->0.027144) \t Saving The Model\n","In epoch 6, loss: 0.358, val acc: 0.600, val_loss: 0.120\n","In epoch 7, loss: 0.298, val acc: 0.967, val_loss: 0.231\n","In epoch 8, loss: 0.315, val acc: 1.000, val_loss: 0.004\n","Validation Loss Decreased(0.027144--->0.004360) \t Saving The Model\n","In epoch 9, loss: 0.293, val acc: 0.833, val_loss: 1.034\n","In epoch 10, loss: 0.248, val acc: 1.000, val_loss: 0.093\n"]}]},{"cell_type":"code","source":["model = Network()\n","model.load_state_dict(torch.load('/content/saved_model.pth'))\n","\n","correct = 0\n","with torch.no_grad():\n","    for data, target in val_loader:\n","        output = model(data)\n","\n","        predicted = torch.argmax(output, 1)\n","        correct += (predicted == target).sum().item()\n","    \n","    accuracy = correct / len(val_loader)\n","    print(f'Test Accuracy: {accuracy}')     "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHoMTks8rZJX","executionInfo":{"status":"ok","timestamp":1659111231490,"user_tz":-480,"elapsed":4,"user":{"displayName":"Zih-Hao Huang","userId":"01538250339568169750"}},"outputId":"3405993a-3d98-4550-f837-90df26c106f4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 1.0\n"]}]}]}